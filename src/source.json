{
    "complexitiesO":
        [
            {
                "symbol": "O(NlogN)",
                "examples":
                    [
                        {"name": "Mergesort",
                        "gif": "merge.gif"},
                        {"name": "Timsort",
                        "gif": "placeholderRectangle.png"},
                        {"name": "Heapsort",
                        "gif": "heap.gif"},
                        {"name": "Quicksort",
                        "gif": "quick.gif"}
                    ],
                "image": "NlogN.png",
                "description": "NLOGN Description goes here",
                "rank": 6
            },
            {
                "symbol": "O(N^2)",
                "examples":
                    [
                        {"name": "Bubble sort",
                         "gif": "bubble.gif",
                         "description": "The simplest sorting algorithm that works by repeatedly swapping the adjacent elements if they are in the wrong order. This algorithm is not suitable for large data sets as its average and worst-case time complexity is quite high."},
                         {"name": "Insertion sort",
                         "gif": "insertion.gif"},
                        {"name": "Selection sort",
                         "gif": "selection.gif"},
                        {"name": "Tree sort",
                         "gif": "tree.gif"},
                        {"name": "Bucket Sort",
                         "gif": "bucket.gif"}
                    ],
                "image": "N2.png",
                "description": "Quadratic time complexity. Often reflects the fact that the algorithm processes all (or a substantial number of) pairs of elements in a given input set. In the code it usually looks like a for loop embedded inside of another for loop. The examples are basic sorting algorithms like bubble, insertion or selection sort.",
                "resources": [],
                "rank": 8
            }, 
            {
                "symbol": "O(N(logN)^2)",
                "examples": 
                    [
                        {"name": "Shell sort",
                        "gif": "shell.gif"}
                    ],
                "image": "NlogN2.png",
                "description": "NLOGN2 Description goes here",
                "rank": 7
            },
            {"symbol": "O(NK)",
            "examples": 
                [
                    {"name": "Radix sort",
                     "gif": "radix.gif",
                     "description": "Radix Sort is a linear sorting algorithm. Radix Sort's time complexity of O(nd), where n is the size of the array and d is the number of digits in the largest number. It is not an in-place sorting algorithm because it requires extra space. The time complexity of radix sort is O(n) because each digit is sorted independently. Some consider Radix sort to have a time complexity of O(N)."}
                ],
                "image": "NK.png",
                "description": "NK Description goes here",
                 "rank": 5},
            {
                "symbol": "O(N+K)",
                "examples": 
                    [
                        {"name": "Counting sort",
                        "gif": "counting.gif"}
                    ],
                "image": "NplusK.png",
                "description": "N+K Description goes here",
                "rank": 4},
            {
                "symbol": "O(N)",
                "examples": 
                    [],
                "image": "N.png",
                "description": "As N increases, so does the amount of operations needed to complete the problem. This is simple to understand because itâ€™s an entirely linear relationship.",
                "rank": 3},
            {
                "symbol": "O(1)",
                "examples": 
                    [],
                "image": "1.png",
                "description": "Constant time",
                "rank": 1
            },
            {
                "symbol": "O(2^N)",
                "examples": 
                    [],
                "image": "2N.png",
                "description": "Worst time",
                "rank": 9
            },
            {
                "symbol": "O(log(N))",
                "examples": 
                    [
                        {
                            "name": "binary search",
                            "gif": "binary.gif"
                        }
                    ],
                "image": "logN.png",
                "description": "Good time",
                "rank": 2
            }

        ],
    "review-questions": {
        "basics": [],
        "data structures": [
            {
                "image": "minheap1.png",
                "question": "The following is a valid binary min heap. (T/F)",
                "answer": "True",
                "context": "In a Min Binary Heap, the key at the root must be minimum among all keys present in Binary Heap. The same property must be recursively true for all nodes in Binary Tree."
            }
        ],
        "algorithms": [
            {
                "question": "Quick sort running time depends on the selection of the _ .",
                "answer": "pivot element",
                "context": "If the pivot element is balanced, quick sort running time will be less."
            },
            {
                "question": "An adaptive sorting algorithm takes advantage of _ elements.",
                "answer": "sorted"
            },
            {
                "question": "Which sorting algorithms maintain two sub-lists, one sorted and one to be sorted?",
                "answer": "Selection sort and insertion sort.",
                "context": "Both maintain two sublists and then check the unsorted list for next sorted element."
            }
        ],
        "complexities": []
    }
}